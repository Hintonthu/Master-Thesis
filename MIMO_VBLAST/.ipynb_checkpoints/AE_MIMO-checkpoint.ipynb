{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MIMO model (V-BLAST orientated --> no CSIT) - Training an end-to-end communications system on a Rayleigh-Fading channel based on an autoencoder model\n",
    "\n",
    "This model is modified explicitly for the MISO scenario and using STBC encoding\n",
    "\n",
    "Hint: To prevent memory garbage on disk suppress summary generation when not explicitly desired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import itertools as it\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Ignore if you do not have multiple GPUs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section defines the parameters which need to be fed to the model for the initializiation process\n",
    "\n",
    "- Be aware that the parameters influence the size of the neural networks\n",
    "- k is the number of information bits per channel usage, note that the number of possible messages is T = 2**(k*mt)\n",
    "- n is the number of complex channel uses per message, is here fixed to n=1 !!\n",
    "- seed can be used to reproduce identical results by fixing the seed of the random number generators, note that the line \"tf.set_random_seed(self.seed)\" should be commented out to set the seed in the graph, otherwise 'seed' is only used to distinguish between trained models in the saving process\n",
    "- mt and mr are the number of transmit and recive antenna respectively, in MISO mr is fixed to one\n",
    "    mt influences the dimension of the transmitted STBC, the dimension is fixed to mt x 1!\n",
    "- model_file_1 and model_file_2 are only declared to distinguish models in saving processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3 # Number of information bits per channel usage\n",
    "n = 1 # Number of complex channel uses per message\n",
    "seed = 1 # Seed RNG reproduce identical results\n",
    "mt = 2\n",
    "mr = 2\n",
    "model_file_1 = 'MIMO_VBLAST/' \n",
    "model_file_2 = '_k_{}_n_{}_tx_{}_rx_{}_s_{}'.format(k, n, mt, mr, seed)\n",
    "\n",
    "\n",
    "assert n is 1, \"n does not equal 1\"\n",
    "assert mt == mr, \"Number of Transmit and Receive antennas is not equal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Autoencoder with subfunctions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AE(object):\n",
    "    def __init__(self, k, n, mt, mr, seed=None, filename=None):\n",
    "        '''This function is the initialization function of the Autoencoder class'''\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "        self.mt = mt\n",
    "        self.mr = mr\n",
    "        self.bits_per_symbol = self.k / self.n\n",
    "        self.M = 2 ** self.k\n",
    "        self.T = 2 ** (self.mt * self.k)  # Anzahl m√∂glicher Tupel\n",
    "        self.seed = seed if (seed is not None) else int(time.time())\n",
    "        self.graph = None\n",
    "        self.sess = None\n",
    "        self.vars = None\n",
    "        self.saver = None\n",
    "        self.constellations = None\n",
    "        self.blers = None\n",
    "        self.create_graph()\n",
    "        self.create_session()\n",
    "        self.sum = self.sum_writer()\n",
    "        if filename is not None:\n",
    "            self.load(filename)\n",
    "        return\n",
    "\n",
    "    def create_graph(self):\n",
    "        '''This function creates the computation graph of the autoencoder'''\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            \n",
    "            # Comment out if you want to set the RNG seed\n",
    "            #tf.set_random_seed(self.seed)\n",
    "            \n",
    "            # Placeholder which defines the input of the AE\n",
    "            batch_size = tf.placeholder(tf.int32, shape=())\n",
    "            \n",
    "            # Create Channelmatrix\n",
    "            hc, h_resh = self.channel_matrix()\n",
    "\n",
    "            # Transmitter\n",
    "            s = tf.random_uniform(shape=[batch_size], minval=0, maxval=self.T, dtype=tf.int64)\n",
    "            x, x_plot, vars_enc = self.encoder(s, h_resh)\n",
    "\n",
    "            # Channel\n",
    "            noise_std = tf.placeholder(tf.float32, shape=())\n",
    "            y = self.channel(x, hc, noise_std)\n",
    "\n",
    "            # Receiver RTN\n",
    "            yc_rtn, h_hat_dec, _ = self.predecode(y, h_resh)\n",
    "            s_hat, vars_dec = self.decoder(yc_rtn, h_resh)\n",
    "\n",
    "            # Loss function\n",
    "            cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=s, logits=s_hat)\n",
    "\n",
    "            # Performance metrics\n",
    "            preds = tf.nn.softmax(s_hat)\n",
    "            s_hat_bit = tf.argmax(preds, axis=1)\n",
    "            correct_predictions = tf.equal(s_hat_bit, s)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "            bler = 1 - accuracy\n",
    "\n",
    "            # Optimizer\n",
    "            lr = tf.placeholder(tf.float32, shape=())  # We can feed in any desired learning rate for each step\n",
    "            train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    "            \n",
    "            # Code lines which need to be implemented to monitor AE behavior through Tensorboard \n",
    "            with tf.name_scope('performance'):\n",
    "                tf.summary.scalar('loss', cross_entropy)\n",
    "                tf.summary.scalar('bler', bler)\n",
    "            \n",
    "            train_vars = tf.trainable_variables()#tf.get_variable('enc_2/kernel')\n",
    "            train_v = [vars_enc, vars_dec]\n",
    "            \n",
    "            merged = tf.summary.merge_all()\n",
    "\n",
    "            # References to graph variables we need to access later\n",
    "            self.vars = {\n",
    "                'accuracy': accuracy,\n",
    "                'batch_size': batch_size,\n",
    "                'bler': bler,\n",
    "                'cross_entropy': cross_entropy,\n",
    "                'init': tf.global_variables_initializer(),\n",
    "                'lr': lr,\n",
    "                'noise_std': noise_std,\n",
    "                'train_op': train_op,\n",
    "                's': s,\n",
    "                's_hat': s_hat,\n",
    "                'x': x,\n",
    "                'h': hc,\n",
    "                'y': y,\n",
    "                'x_plot': x_plot,\n",
    "                'hc': hc,\n",
    "                's_hat_bit': s_hat_bit,\n",
    "                'preds': preds,\n",
    "                'merged': merged,\n",
    "                'train_vars': train_vars,\n",
    "                'train_v': train_v,\n",
    "                'yc_rtn': yc_rtn,\n",
    "                'h_hat_dec': h_hat_dec,\n",
    "                'corr_preds': correct_predictions\n",
    "            }\n",
    "            self.saver = tf.train.Saver()\n",
    "        return\n",
    "\n",
    "    def create_session(self):\n",
    "        '''Create a session for the autoencoder instance with the compuational graph'''\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "        self.sess.run(self.vars['init'])\n",
    "        return\n",
    "\n",
    "    def channel_matrix(self):\n",
    "        '''The Channel Matrix Calculation (Rayleigh Fading Channel)'''\n",
    "        \n",
    "        # Define standard deviation as Rayleigh\n",
    "        h_std_r = np.sqrt(0.5)\n",
    "        h_mean_r = 0\n",
    "        h_std_i = np.sqrt(0.5)\n",
    "        h_mean_i = 0\n",
    "        \n",
    "        # Calculate channel symbols\n",
    "        hr = tf.random_normal([self.mt, self.mr], mean=h_mean_r, stddev=h_std_r, dtype=tf.float32)\n",
    "        hi = tf.random_normal([self.mt, self.mr], mean=h_mean_i, stddev=h_std_i, dtype=tf.float32)\n",
    "        hc = tf.complex(hr, hi)\n",
    "        \n",
    "        # Channel in real notation\n",
    "        h = tf.concat([tf.real(hc), tf.imag(hc)], axis=1)\n",
    "        h_resh = tf.reshape(h, shape=[1, -1])\n",
    "\n",
    "        return hc, h_resh\n",
    "  \n",
    "    def encoder(self, input, h):\n",
    "        '''The transmitter'''\n",
    "        \n",
    "        # Embedding Layer  \n",
    "        with tf.name_scope('enc_1'):\n",
    "            # Embedding Matrix\n",
    "            W = self.weight_variable((self.T, self.T))\n",
    "            # Embedding Look-Up and ELU-Activation\n",
    "            x = tf.nn.elu(tf.nn.embedding_lookup(W, input), name='enc_1')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_enc_1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'enc_1')\n",
    "            \n",
    "        # Hidden Layer\n",
    "        with tf.name_scope('enc_2'):\n",
    "            # Dense Layer\n",
    "            x = tf.layers.dense(x, self.mt * self.M, activation=tf.nn.leaky_relu, name='enc_2')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_enc_2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'enc_2')\n",
    "        \n",
    "        # Hidden Layer\n",
    "        with tf.name_scope('enc_3'):\n",
    "            # Dense Layer\n",
    "            x = tf.layers.dense(x, 2 * self.mt * self.mt, activation=tf.nn.leaky_relu, name='enc_3')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_enc_3 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'enc_3')\n",
    "        \n",
    "        # Output Layer\n",
    "        with tf.name_scope('enc_4'):\n",
    "            # Dense Layer\n",
    "            x = tf.layers.dense(x, 2 * self.mt, activation=None, name='enc_4')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_enc_4 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'enc_4')\n",
    "        \n",
    "        # Concat all summaries of the layer parameters\n",
    "        vars = [var_enc_1, var_enc_2, var_enc_3, var_enc_4]\n",
    "        \n",
    "        # Real to complex transformation\n",
    "        x = tf.reshape(x, shape=[-1, 2])\n",
    "        x = tf.reshape(tf.complex(x[::, 0], x[::, 1]), shape=[-1, 1])\n",
    "         \n",
    "        # Power Normalization (Comment out the one you want to use)\n",
    "        \n",
    "        # Average power normalization over all\n",
    "        norma = tf.sqrt(tf.reduce_mean(tf.square(tf.abs(x)), axis=0))\n",
    "        x = x / tf.cast(norma, dtype=tf.complex64)\n",
    "        '''\n",
    "        # Power Normalization = 1\n",
    "        norma = tf.reciprocal(tf.sqrt(tf.square(tf.abs(x))))\n",
    "        x = tf.multiply(x, tf.cast(norma, dtype=tf.complex64))\n",
    "        '''\n",
    "    \n",
    "        #Antenna Mapping\n",
    "        x = tf.reshape(x, shape=[-1, self.mt])\n",
    "        \n",
    "        '''\n",
    "        # Average power normalization over each antenna\n",
    "        norma = tf.sqrt(tf.reduce_mean(tf.square(tf.abs(x)), axis=0))\n",
    "        x = x / tf.cast(norma, dtype=tf.complex64)\n",
    "        '''\n",
    "                    \n",
    "        # x_plot needs to be reshaped sometimes for plotting purposes\n",
    "        x_plot = x\n",
    "                \n",
    "        return x, x_plot, vars\n",
    "\n",
    "    def channel(self, xc, hc, noise_std):\n",
    "        '''The channel'''  \n",
    "        \n",
    "        # Channel Matrix Multiplication\n",
    "        yc = tf.matmul(xc, hc)\n",
    "        \n",
    "        # Noise\n",
    "        nr = tf.random_normal(tf.shape(yc), mean=0.0, stddev=(noise_std/np.sqrt(2)), dtype=tf.float32)\n",
    "        ni = tf.random_normal(tf.shape(yc), mean=0.0, stddev=(noise_std/2), dtype=tf.float32)\n",
    "        nc = tf.complex(nr, ni)\n",
    "        yc = tf.add(yc, nc)\n",
    "        \n",
    "        return yc\n",
    "          \n",
    "    def predecode(self, yc, h):\n",
    "        '''Predecoder-NN with Zero-Forcing Orientation (Input: Received Symbols plus CSI)'''\n",
    "        \n",
    "        # Complex to real Transformation\n",
    "        yc = tf.reshape(yc, shape=[-1, 1])\n",
    "        y = tf.concat([tf.real(yc), tf.imag(yc)], axis=1)     \n",
    "        y = tf.reshape(y, shape=[-1, 2*self.mr])\n",
    "        \n",
    "        # Concat CSIR to y\n",
    "        h = tf.tile(h, [tf.shape(y)[0], 1])\n",
    "        input = tf.concat([y, h], 1)\n",
    "        \n",
    "        # Input Layer\n",
    "        with tf.name_scope('pre_d1'):\n",
    "            # Dense Layer\n",
    "            h_hat = tf.layers.dense(input, 20, activation=tf.tanh, name='pre_d1')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_pre_1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'pre_d1')\n",
    "            \n",
    "        # Hidden Layer    \n",
    "        with tf.name_scope('pre_d2'):\n",
    "            # Dense Layer\n",
    "            h_hat = tf.layers.dense(h_hat, 12, activation=tf.tanh, name='pre_d2')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_pre_2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'pre_d2')\n",
    "            \n",
    "        # Output Layer    \n",
    "        with tf.name_scope('pre_d3'):\n",
    "            # Dense Layer\n",
    "            h_hat = tf.layers.dense(h_hat, 2 * self.mt * self.mr, activation=None, name='pre_d3')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_pre_3 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'pre_d3')\n",
    "        \n",
    "        # Concat all summaries of the layer parameters\n",
    "        vars = [var_pre_1, var_pre_2, var_pre_3]\n",
    "        \n",
    "        # Real to Complex and reshape to right Dimensions\n",
    "        h_hat = tf.reshape(h_hat, shape=[-1, 2])\n",
    "        h_hat = tf.complex(h_hat[:, 0], h_hat[:, 1])\n",
    "        h_hat = tf.reshape(h_hat, shape=[-1, self.mt * self.mr])\n",
    "        h_hat = tf.reduce_mean(h_hat, axis=0)\n",
    "        h_hat = tf.reshape(h_hat, shape=[self.mr, -1])\n",
    "        \n",
    "        # Multiplication of learned Matrix with received Symbols\n",
    "        yc = tf.reshape(yc, shape=[-1, self.mr])\n",
    "        yc_rtn = tf.matmul(yc, h_hat)        \n",
    "        \n",
    "        return yc_rtn, h_hat, vars\n",
    "    \n",
    "    def decoder(self, yc, h):\n",
    "        '''The Receiver (Decoder-NN)'''\n",
    "        \n",
    "        # Complex to real plus reshape to Dimension as in Output Vector of Encoder-NN\n",
    "        yc = tf.reshape(yc, shape=[-1, 1])\n",
    "        y = tf.concat([tf.real(yc), tf.imag(yc)], axis=1)     \n",
    "        y = tf.reshape(y, shape=[-1, 2*self.mt])\n",
    "\n",
    "        input = y\n",
    "        \n",
    "        # Input Layer\n",
    "        with tf.name_scope('dec_1'):\n",
    "            # Dense Layer\n",
    "            y = tf.layers.dense(input, self.mr*self.T, activation=tf.nn.leaky_relu, name='dec_1')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_dec_1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'dec_1')\n",
    "            \n",
    "        # Hidden Layer\n",
    "        with tf.name_scope('dec_2'):\n",
    "            # Dense Layer\n",
    "            y = tf.layers.dense(y, self.mr*self.T, activation=tf.nn.leaky_relu, name='dec_2')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_dec_2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'dec_2')\n",
    "            \n",
    "        # Hidden Layer\n",
    "        with tf.name_scope('dec_3'):\n",
    "            # Dense Layer\n",
    "            y = tf.layers.dense(y, self.mr*self.T, activation=tf.nn.leaky_relu, name='dec_3')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_dec_3 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'dec_3')\n",
    "            \n",
    "        # Output Layer\n",
    "        with tf.name_scope('dec_4'):\n",
    "            # Dense Layer\n",
    "            y = tf.layers.dense(y, self.T, activation=None, name='dec_4')\n",
    "            # Store layer parameters to monitor them in Tensorboard\n",
    "            var_dec_4 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'dec_4')\n",
    "        \n",
    "        # Concat all summaries of the layer parameters \n",
    "        vars = [var_dec_1, var_dec_2, var_dec_3, var_dec_4]\n",
    "       \n",
    "        return y, vars\n",
    "\n",
    "    def EbNo2Sigma(self, ebnodb):\n",
    "        '''Convert Eb/No in dB to noise standard deviation'''\n",
    "        ebno = 10 ** (ebnodb / 10)\n",
    "        return np.sqrt(1 / ((1 / self.mt) * self.mt * self.bits_per_symbol * ebno)) # Rate\n",
    "\n",
    "    def gen_feed_dict(self, batch_size, ebnodb, lr):\n",
    "        '''Generate a feed dictionary for training and validation'''\n",
    "        return {\n",
    "            self.vars['batch_size']: batch_size,\n",
    "            self.vars['noise_std']: self.EbNo2Sigma(ebnodb),\n",
    "            self.vars['lr']: lr,\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch_size, ebnodb):\n",
    "        '''Compute the BLER over a single batch and Eb/No'''\n",
    "        bler = self.sess.run(self.vars['bler'], feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr=0))\n",
    "        return bler\n",
    "\n",
    "    def train(self, training_params, validation_params):\n",
    "        '''Main training function, which handles train and validation paramters'''\n",
    "        \n",
    "        # Training and validation loop\n",
    "        for index, params in enumerate(training_params):\n",
    "            batch_size, lr, ebnodb, iterations, repeats = params\n",
    "            print('\\nBatch Size: ' + str(batch_size) +\n",
    "                  ', Learning Rate: ' + str(lr) +\n",
    "                  ', EbNodB: ' + str(ebnodb) +\n",
    "                  ', Iterations: ' + str(iterations) +\n",
    "                  ', Repeats: ' + str(repeats))\n",
    "\n",
    "            val_size, val_ebnodb, val_steps = validation_params[index]\n",
    "            \n",
    "            for j in range(repeats):          \n",
    "                for i in range(iterations):\n",
    "                    \n",
    "                    # Call training function\n",
    "                    self.train_step(batch_size, ebnodb, lr)\n",
    "                    \n",
    "                    # Observe val results\n",
    "                    if i%val_steps==0 and index==0 and j==0:\n",
    "                        bler = self.sess.run(self.vars['bler'], feed_dict=self.gen_feed_dict(val_size, val_ebnodb, lr))\n",
    "                        print(bler)\n",
    "           \n",
    "            bler = self.sess.run(self.vars['bler'], feed_dict=self.gen_feed_dict(val_size, val_ebnodb, lr))\n",
    "            print(bler)\n",
    "            \n",
    "        return\n",
    "\n",
    "    def train_step(self, batch_size, ebnodb, lr):\n",
    "        '''A single training step: Computes one iteration of the graph and  optimizes neural net paramters'''\n",
    "        summary, _ = self.sess.run([self.vars['merged'], self.vars['train_op']], feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr))\n",
    "        return summary\n",
    "    \n",
    "    def sum_writer(self):\n",
    "        '''Summary writer function which is needed for Tensorboard visualization'''\n",
    "        sum_writer = tf.summary.FileWriter(model_file_1 + 'Summary', self.sess.graph)\n",
    "        return sum_writer\n",
    "\n",
    "    def get_graphkeys(self):\n",
    "        '''Get the trained weights and biases of the layers'''\n",
    "        theta = self.sess.run(self.vars['train_v'])\n",
    "        return theta\n",
    "\n",
    "    def weight_variable(self, shape):\n",
    "        '''Xavier-initialized weights in Embedding Matrix'''\n",
    "        (fan_in, fan_out) = shape\n",
    "        low = np.sqrt(6.0 / (fan_in + fan_out))\n",
    "        high = -np.sqrt(6.0 / (fan_in + fan_out))\n",
    "        return tf.Variable(tf.random_uniform(shape, minval=low, maxval=high, dtype=tf.float32))\n",
    "    \n",
    "    def save(self, filename):\n",
    "        '''Save the current model'''\n",
    "        return self.saver.save(self.sess, filename)\n",
    "    \n",
    "    def load(self, filename):\n",
    "        '''Load an pre_trained model'''\n",
    "        return self.saver.restore(self.sess, filename)\n",
    "\n",
    "    def plot_constellation(self, maxrange=None):\n",
    "        '''Generate a plot of the current constellation overall antennas'''\n",
    "        \n",
    "        # Get symbols \n",
    "        x = self.transmit(range(self.T))\n",
    "        x = np.reshape(x, (self.T, self.mt))\n",
    "        \n",
    "        # Define plot parameters\n",
    "        if (maxrange is None):\n",
    "            maxrange = np.max(np.abs(x))\n",
    "        colours = cm.cmap_d['gist_rainbow'](np.linspace(0, 1, self.T))\n",
    "        image = plt.figure(figsize=(6, 6))\n",
    "        plt.grid(True)\n",
    "        plt.xlim(-maxrange, maxrange)\n",
    "        plt.ylim(-maxrange, maxrange)\n",
    "        \n",
    "        # Calculate bit-block assignement\n",
    "        bit_assigned = self.assign_bits_to_msg(100, 30, 10000)\n",
    "        \n",
    "        # Plot symbols\n",
    "        for j in range(self.T):\n",
    "            for k in range(self.mt):\n",
    "                if k == 0:\n",
    "                    plt.scatter(x[j, k].real, x[j, k].imag, marker='x', label=bit_assigned[j], c=colours[j])\n",
    "                else:\n",
    "                    plt.scatter(x[j, k].real, x[j, k].imag, marker='x', c=colours[j])\n",
    "                plt.annotate(k, (x[j, k].real+0.05, x[j, k].imag+0.05))\n",
    "                \n",
    "        plt.legend(bit_assigned, loc='upper center', bbox_to_anchor=(1.2,1), ncol=1, fontsize=16, handletextpad=0.05, labelspacing=0.2)\n",
    "        parameter = {\"ytick.color\": \"k\", \"xtick.color\": \"k\", \"axes.labelcolor\": \"k\", \"axes.edgecolor\": \"k\"}\n",
    "        plt.xlabel('I', fontsize=18)\n",
    "        plt.ylabel('Q', fontsize=18)\n",
    "        plt.tick_params(labelsize=16)\n",
    "        plt.rcParams.update(parameter)\n",
    "        image.axes[0].set_xticks(np.array([-2, -1, 0, 1, 2]))                                          \n",
    "        image.axes[0].set_yticks(np.array([-2, -1, 0, 1, 2]))\n",
    "        return x, image\n",
    "    \n",
    "    def plot_const_antwise(self, maxrange=None):\n",
    "        '''Generate a plot of the current constellation with subplots over each different antenna'''\n",
    "        \n",
    "        # Get symbols \n",
    "        x = self.transmit(range(self.T))\n",
    "        \n",
    "        # Define plot parameters\n",
    "        if (maxrange is None):\n",
    "            maxrange = np.max(np.abs(x))\n",
    "        colours = cm.cmap_d['gist_rainbow'](np.linspace(0, 1, self.T))   \n",
    "        num_of_subplts = self.mt\n",
    "        image = plt.figure(figsize=(12, 12))\n",
    "        \n",
    "        # Rehsape x to work with it easier\n",
    "        x = np.reshape(x, (self.T, self.mt))\n",
    "        x = np.transpose(x)\n",
    "        \n",
    "        # Calculate bit-block assignement\n",
    "        bit_assigned = self.assign_bits_to_msg(100, 30, 10000)\n",
    "        \n",
    "        # Plot symbols antenna wise\n",
    "        a = 1 \n",
    "        for k in range(num_of_subplts):\n",
    "            ax = image.add_subplot(self.mt, self.mt, k+1)\n",
    "            for j in range(self.T):\n",
    "                ax.scatter(x[k, j].real, x[k, j].imag, marker='x', label=bit_assigned[j], c=colours[j], s=75)\n",
    "            ax.grid(True)\n",
    "            ax.set_xlim(-maxrange, maxrange)\n",
    "            ax.set_ylim(-maxrange, maxrange)\n",
    "                \n",
    "            title = 'Antenne {}'.format(a)\n",
    "            ax.set_title(title, fontsize=18)\n",
    "            ax.set_xlabel('I', fontsize=18)\n",
    "            ax.set_ylabel('Q', fontsize=18)\n",
    "            ax.tick_params(labelsize=16)\n",
    "            ax.set(adjustable='box-forced', aspect='equal')\n",
    "            if ((k+1) % self.mt) == 0:\n",
    "                a = 1\n",
    "            else:\n",
    "                a += 1\n",
    "            #plt.locator_params(nbins=5)\n",
    "            image.axes[k].set_xticks(np.array([-3, -2, -1, 0, 1, 2, 3]))                                          \n",
    "            image.axes[k].set_yticks(np.array([-3, -2, -1, 0, 1, 2, 3]))\n",
    "                \n",
    "        plt.legend(bit_assigned, loc='upper center', bbox_to_anchor=(1.35,1.1), ncol=1, fontsize=16, handletextpad=0.05, labelspacing=0.2) \n",
    "        image.tight_layout()\n",
    "        parameter = {\"ytick.color\": \"k\", \"xtick.color\": \"k\", \"axes.labelcolor\": \"k\", \"axes.edgecolor\": \"k\"}\n",
    "        plt.rcParams.update(parameter)\n",
    "        plt.subplots_adjust(wspace=0.4, hspace=0.4)  \n",
    "        return x, image\n",
    "    \n",
    "    def plot_receive(self, ebn0, channel_realizations, rtn=0, maxrange=None):\n",
    "        '''Generate a plot of the received constellation (Be Aware: with rtn = 0 or 1 you influence \n",
    "                    whether you want to plot the symbols before or after the Predecoder-NN'''\n",
    "        \n",
    "        # Get Symbols\n",
    "        if rtn == 1:\n",
    "            y = self.receive_RTN(ebn0, channel_realizations)\n",
    "        else:\n",
    "            y = self.receive(ebn0, channel_realizations)\n",
    "            \n",
    "        # Define plot parameters      \n",
    "        if (maxrange is None):\n",
    "            maxrange = np.max(np.abs(y))\n",
    "        colours = cm.cmap_d['gist_rainbow'](np.linspace(0, 1, self.T)) \n",
    "        image = plt.figure(figsize=(12, (12/self.mr)))\n",
    "        \n",
    "        # Calculate bit assignment\n",
    "        bit_assigned = self.assign_bits_to_msg(100, 30, 10000)\n",
    "        \n",
    "        # Plot symbols before Predecoding\n",
    "        if rtn == 0:\n",
    "            for i in range(self.mr):\n",
    "                ax = image.add_subplot(1, self.mr, i+1)\n",
    "                \n",
    "                ax.grid(True)\n",
    "                ax.set_xlim(-maxrange, maxrange)\n",
    "                ax.set_ylim(-maxrange, maxrange)\n",
    "\n",
    "                for j in range(channel_realizations):\n",
    "                    symbols = y[j]\n",
    "                    for k in range(self.T):\n",
    "                        if j == 0 and i == 0:\n",
    "                            ax.scatter(symbols[k, i].real, symbols[k, i].imag, c=colours[k], marker='x', label='s{}'.format(k), s=75)\n",
    "                        else:\n",
    "                            ax.scatter(symbols[k, i].real, symbols[k, i].imag, c=colours[k], marker='x')\n",
    "                            \n",
    "                title = 'Antenne {} '.format(i+1)\n",
    "                ax.set_title(title, fontsize=18)\n",
    "                ax.set_xlabel('I', fontsize=18)\n",
    "                ax.set_ylabel('Q', fontsize=18)\n",
    "                ax.tick_params(labelsize=16)\n",
    "                ax.set(adjustable='box-forced', aspect='equal')\n",
    "        \n",
    "        # Plot symbols after Predecoding\n",
    "        if rtn == 1:\n",
    "            for i in range(self.mt):\n",
    "                ax = image.add_subplot(1, self.mt, i+1)\n",
    "                \n",
    "                ax.grid(True)\n",
    "                ax.set_xlim(-maxrange, maxrange)\n",
    "                ax.set_ylim(-maxrange, maxrange)\n",
    "                for j in range(channel_realizations):\n",
    "                    symbols = y[j]\n",
    "                    for k in range(self.T):\n",
    "                        if j == 0 and i == 0:\n",
    "                            ax.scatter(symbols[k, i].real, symbols[k, i].imag, c=colours[k], marker='x', label='s{}'.format(k), s=75)\n",
    "                        else:\n",
    "                            ax.scatter(symbols[k, i].real, symbols[k, i].imag, c=colours[k], marker='x')\n",
    "                            \n",
    "                title = 'Antenne {} '.format(i+1)\n",
    "                ax.set_title(title, fontsize=18)\n",
    "                ax.set_xlabel('I', fontsize=18)\n",
    "                ax.set_ylabel('Q', fontsize=18)\n",
    "                ax.tick_params(labelsize=16)\n",
    "                ax.set(adjustable='box-forced', aspect='equal')\n",
    "        \n",
    "        plt.legend(bit_assigned, loc='upper center', bbox_to_anchor=(1.3,1), ncol=1, fontsize=16, handletextpad=0.05, labelspacing=0.2)\n",
    "        image.tight_layout()\n",
    "        parameter = {\"ytick.color\": \"k\", \"xtick.color\": \"k\", \"axes.labelcolor\": \"k\", \"axes.edgecolor\": \"k\"}\n",
    "        plt.xlabel('I', fontsize=18)\n",
    "        plt.ylabel('Q', fontsize=18)\n",
    "        plt.tick_params(labelsize=16)\n",
    "        plt.rcParams.update(parameter)\n",
    "        \n",
    "        return y, \n",
    "    \n",
    "    def transmit(self, s):\n",
    "        '''Returns the transmitted signals corresponding to message indices (BE AWARE: RETURNS x_plot and not x!)'''\n",
    "        return self.sess.run(self.vars['x_plot'], feed_dict={self.vars['s']: s})\n",
    "    \n",
    "    def receive(self, ebnodb, channel_realizations):\n",
    "        '''Returns the received signals of multiple sending of the T consecutive messages\n",
    "                            Returns: Array of T x channel_realizations'''\n",
    "        y_ch = []\n",
    "        s = range(self.T)\n",
    "        noise_std = self.EbNo2Sigma(ebnodb)\n",
    "        for i in range(channel_realizations):\n",
    "            y = self.sess.run(self.vars['y'], feed_dict={self.vars['s']: s, self.vars['noise_std']: noise_std})\n",
    "            y_ch.append(y)        \n",
    "        \n",
    "        return y_ch\n",
    "    \n",
    "    def receive_RTN(self, ebnodb, channel_realizations):\n",
    "        '''Returns the symbols after the RTN by multiple sending of the T consecutive messages \n",
    "                            Returns: Array of T x channel_realizations'''\n",
    "        y_ch = []\n",
    "        s = range(self.T)\n",
    "        noise_std = self.EbNo2Sigma(ebnodb)\n",
    "        for i in range(channel_realizations):\n",
    "            y = self.sess.run(self.vars['yc_rtn'], feed_dict={self.vars['s']: s, self.vars['noise_std']: noise_std})\n",
    "            y_ch.append(y)        \n",
    "        \n",
    "        return y_ch \n",
    "    \n",
    "    def bler_sim(self, ebnodbs, batch_size, iterations):\n",
    "        '''Monte Carlo simulations of BLER for a range of Eb/No. average over multiple batches with small size ''' \n",
    "        BLER = np.zeros_like(ebnodbs)\n",
    "        for i in range(iterations):\n",
    "            bler = np.array([self.sess.run(self.vars['bler'],\n",
    "                            feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr=0)) for ebnodb in ebnodbs])\n",
    "            BLER = BLER + bler/iterations\n",
    "            \n",
    "        return BLER\n",
    "    \n",
    "    def plot_bler(self, EbNodB, BLER):\n",
    "        '''Plot a BLER curve'''\n",
    "        image = plt.figure(figsize=(10,8))\n",
    "        plt.plot(EbNodB, BLER, '-r', linewidth=2.0)\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('EbNo (dB)', fontsize=18)\n",
    "        plt.ylabel('Block-error rate', fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.ylim([1e-5, 1])\n",
    "        parameter = {\"ytick.color\": \"k\", \"xtick.color\": \"k\", \"axes.labelcolor\": \"k\", \"axes.edgecolor\": \"k\"}\n",
    "        plt.rcParams.update(parameter)\n",
    "        plt.legend(['Autoencoder'], prop={'size': 16}, loc='upper right')\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def assign_bits_to_msg(self, batch_size, ebnodb, channel_realisations):\n",
    "        '''Compute bit assignment to message indices: Get average BER over batchsize on multiple channelrealizations \n",
    "                for specific EbN0; Take the bit assignment which produces lowest BER'''\n",
    "        \n",
    "        prob_arr = []\n",
    "        \n",
    "        # Average the prediction probabilities for each message when decoded over a loop\n",
    "        for i in range(channel_realisations):            \n",
    "            prob = np.zeros((self.T, self.T))\n",
    "            s, preds = self.sess.run([self.vars['s'], self.vars['preds']], feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr=0))\n",
    "            \n",
    "            for ind, msg in enumerate(s):\n",
    "                prob[msg] = prob[msg] + preds[ind]\n",
    "                \n",
    "            unique, counts = np.unique(s, return_counts=True)\n",
    "            occurence = dict(zip(unique, counts))           \n",
    "        \n",
    "            for msg, cnts in occurence.items():\n",
    "                if (cnts == 0):\n",
    "                    prob[msg] = prob[msg]\n",
    "                else:\n",
    "                    prob[msg] = prob[msg] / cnts\n",
    "                    \n",
    "            prob_arr.append(prob)\n",
    "            \n",
    "        prob = np.mean(prob_arr, axis=0)\n",
    "        \n",
    "        # Try out all bit assignments possible for the bitblocks and compute BER\n",
    "        bit_one = []\n",
    "        bit_list = []\n",
    "        msg_list = list(map(list, it.product([0, 1], repeat=(self.k*self.mt))))\n",
    "        \n",
    "        for k in range(len(msg_list)):\n",
    "            msg_list = np.roll(msg_list, k)\n",
    "            bit_list.append(msg_list)\n",
    "            bit_err = []\n",
    "            # Compute Hamming Distance of the bitblock assignment (== # of bit errors if wrongly predicted)\n",
    "            for i in range(len(msg_list)):\n",
    "                for j in range(len(msg_list)):\n",
    "                    hamming_dist = np.sum(np.bitwise_xor(msg_list[i], msg_list[j]))\n",
    "                    bit_err.append(hamming_dist)\n",
    "            \n",
    "            # Calculate BER with hamming dist matrix and prediction probabilities\n",
    "            bit_err = np.reshape(np.asarray(bit_err), (self.T, self.T))\n",
    "            bit_prob = np.multiply(prob, bit_err) / (self.T*self.k*self.mt)\n",
    "            bit_one.append(np.mean(bit_prob))\n",
    "        \n",
    "        # Check for the assigmnent with lowest BER\n",
    "        index_min_BER = np.argmin(bit_one)\n",
    "        assigned_bits = bit_list[int(index_min_BER)]\n",
    "               \n",
    "        return assigned_bits\n",
    "    \n",
    "    def calc_BER(self, batch_size, ebnodb, channel_realisations, assigned_bits):\n",
    "        '''Calculate average BER over a ebno-level with batchsize messages per iterations \n",
    "                            and over # of channel realizations (Monte-Carlo Simulation)'''\n",
    "        \n",
    "        bit_err = []\n",
    "        prob_arr = []\n",
    "        errorsum = 0\n",
    "        \n",
    "        # Average the prediction probabilities for each message when decoded over a loop\n",
    "        for i in range(channel_realisations):            \n",
    "            prob = np.zeros((self.T, self.T))\n",
    "            \n",
    "            # Run graph and get predictions\n",
    "            s, preds, corr_preds = self.sess.run([self.vars['s'], self.vars['preds'], self.vars['corr_preds']], \n",
    "                                     feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr=0))\n",
    "            \n",
    "            for ind, msg in enumerate(s):\n",
    "                prob[msg] = prob[msg] + preds[ind]\n",
    "                \n",
    "            unique, counts = np.unique(s, return_counts=True)\n",
    "            occurence = dict(zip(unique, counts))           \n",
    "        \n",
    "            for msg, cnts in occurence.items():\n",
    "                if (cnts == 0):\n",
    "                    prob[msg] = prob[msg]\n",
    "                else:\n",
    "                    prob[msg] = prob[msg] / cnts\n",
    "                    \n",
    "            prob_arr.append(prob)\n",
    "            \n",
    "            # Count absolute message errors\n",
    "            block_errors_batch = batch_size - np.sum(corr_preds)\n",
    "            errorsum += block_errors_batch\n",
    "            \n",
    "        prob = np.mean(prob_arr, axis=0)\n",
    "        \n",
    "        # Compute Hamming Distance of the bitblock assignment (== # of bit errors if wrongly predicted)\n",
    "        for i in range(len(assigned_bits)):\n",
    "                for j in range(len(assigned_bits)):\n",
    "                    hamming_dist = np.sum(np.bitwise_xor(assigned_bits[i], assigned_bits[j]))\n",
    "                    bit_err.append(hamming_dist)\n",
    "        \n",
    "        # Convert the probability distribution of the predictions to BER with the already assigned bits\n",
    "        bit_err = np.reshape(np.asarray(bit_err), (self.T, self.T))\n",
    "        bit_prob = np.multiply(prob, bit_err) / (self.T*self.k*self.mt) \n",
    "        BER = np.sum(bit_prob)\n",
    "\n",
    "        return BER, errorsum\n",
    "    \n",
    "    def plot_BER(self, batch_size, ebnodbs, channel_realisations, logdir):\n",
    "        '''Plot BER over various ebno-levels'''\n",
    "        \n",
    "        ti = time.time()\n",
    "        ber = []\n",
    "        # Initialize Logfile\n",
    "        logmsg = 'Simulation starting time: ' + str(ti) + '\\n \\n'\n",
    "        with open(logdir, 'w+') as logfile:\n",
    "                        logfile.write(logmsg)\n",
    "        \n",
    "        # Assign bit-blocks to messages    \n",
    "        assigned_bits = self.assign_bits_to_msg(1000, 30, 10000)\n",
    "        \n",
    "        # Iterate over ebno-levels and compute BER with minimum computation and termination citeria\n",
    "        for _, ebno in enumerate(ebnodbs):\n",
    "            i = 1\n",
    "            blockerror_sum = 0\n",
    "            ber_i = []\n",
    "            while True:\n",
    "                ber_val, abs_blockerrors = ae.calc_BER(batch_size, ebno, channel_realisations, assigned_bits)\n",
    "                blockerror_sum += abs_blockerrors\n",
    "                \n",
    "                # Minimum block errors\n",
    "                if (0 <= ebno < 15) and i < 50 and blockerror_sum < 100:\n",
    "                    ber_i.append(ber_val)\n",
    "                    i += 1\n",
    "                    \n",
    "                elif (15 <= ebno < 20) and i < 50 and blockerror_sum < 100:\n",
    "                    ber_i.append(ber_val)\n",
    "                    i += 1\n",
    "                                        \n",
    "                elif (20 <= ebno < 27) and i < 50 and blockerror_sum < 100:\n",
    "                    ber_i.append(ber_val)\n",
    "                    i += 1\n",
    "                                        \n",
    "                elif (27 <= ebno <= 35) and i < 50 and blockerror_sum < 100:\n",
    "                    ber_i.append(ber_val)\n",
    "                    i += 1\n",
    "                \n",
    "                # Min iterations to average\n",
    "                elif (15 <= ebno < 20) and (i < 5):\n",
    "                    ber_i.append(ber_val)\n",
    "                    i += 1\n",
    "                \n",
    "                elif (20 <= ebno < 28) and (i < 10):\n",
    "                    ber_i.append(ber_val)\n",
    "                    i += 1\n",
    "                    \n",
    "                elif (28 <= ebno <= 35) and (i < 15):\n",
    "                    ber_i.append(ber_val)\n",
    "                    i += 1\n",
    "                    \n",
    "                else:\n",
    "                    ber_i.append(ber_val)\n",
    "                    break\n",
    "                    \n",
    "            tim = time.time() - ti\n",
    "            ber_app = np.mean(ber_i, dtype=np.float64) #np.sum(ber_i) / len(ber_i)     \n",
    "            msg = 'EbN0: ' + str(ebno) + ' , Zeit: ' + str(round(tim/60, 2)) + 'min , Averaged over: ' + str(len(ber_i)) + \\\n",
    "                  ', Absolute Blockerrors: ' + str(blockerror_sum) + ', BER: ' + str(np.asscalar(np.round(ber_app, 5))) + '\\n'\n",
    "            print(msg)\n",
    "            with open(logdir, 'a+') as logfile:\n",
    "                logfile.write(msg)\n",
    "            ber.append(ber_app)\n",
    "        \n",
    "        # Plot BER-Curve\n",
    "        image = plt.figure(figsize=(10,8))\n",
    "        plt.plot(ebnodbs, ber, '-r', linewidth=2.0)\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('EbNo (dB)', fontsize=18)\n",
    "        plt.ylabel('avBER', fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.ylim([1e-5, 1])\n",
    "        parameter = {\"ytick.color\": \"k\", \"xtick.color\": \"k\", \"axes.labelcolor\": \"k\", \"axes.edgecolor\": \"k\"}\n",
    "        plt.rcParams.update(parameter)\n",
    "        plt.legend(['Autoencoder'], prop={'size': 16}, loc='upper right')\n",
    "        \n",
    "        return image, ber\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsloop 1 as described in Master's Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Graph... with M = 8\n",
      "Initialized... \n",
      " \n",
      "\n",
      "Training with 3 EbN0 and lr = 0.01\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.01, EbNodB: 3, Iterations: 10000, Repeats: 2\n",
      "0.98722\n",
      "0.66466\n",
      "0.51936\n",
      "0.51821\n",
      "0.63418996\n",
      "0.64636004\n",
      "0.57842004\n",
      "0.79695\n",
      "0.70348\n",
      "0.41215003\n",
      "0.28134\n",
      "\n",
      "Training with 7 EbN0 and lr = 0.00875\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.00875, EbNodB: 7, Iterations: 10000, Repeats: 2\n",
      "0.16728002\n",
      "0.2769\n",
      "0.31923002\n",
      "0.34871\n",
      "0.101580024\n",
      "0.52507997\n",
      "0.31919998\n",
      "0.14477003\n",
      "0.19586003\n",
      "0.30486\n",
      "0.25054997\n",
      "\n",
      "Training with 11 EbN0 and lr = 0.0075\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.0075, EbNodB: 11, Iterations: 10000, Repeats: 2\n",
      "0.57901\n",
      "0.022669971\n",
      "0.14223999\n",
      "0.14064997\n",
      "0.21333998\n",
      "0.03719002\n",
      "0.033469975\n",
      "0.032599986\n",
      "0.06252998\n",
      "0.24720001\n",
      "0.014190018\n",
      "\n",
      "Training with 13 EbN0 and lr = 0.00625\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.00625, EbNodB: 13, Iterations: 10000, Repeats: 2\n",
      "0.29669\n",
      "0.16034001\n",
      "0.02157998\n",
      "0.038810015\n",
      "0.089349985\n",
      "0.00041002035\n",
      "0.21938002\n",
      "0.049600005\n",
      "0.065289974\n",
      "0.0063599944\n",
      "0.15728998\n",
      "\n",
      "Training with 17 EbN0 and lr = 0.005\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.005, EbNodB: 17, Iterations: 10000, Repeats: 2\n",
      "0.00012999773\n",
      "0.017260015\n",
      "0.00036001205\n",
      "0.0026299953\n",
      "0.001330018\n",
      "0.03509003\n",
      "0.00016999245\n",
      "0.11303997\n",
      "2.9981136e-05\n",
      "0.0020899773\n",
      "0.010370016\n",
      "\n",
      "Training with 22 EbN0 and lr = 0.00376\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.00376, EbNodB: 22, Iterations: 10000, Repeats: 2\n",
      "0.0\n",
      "0.00020998716\n",
      "0.0\n",
      "1.001358e-05\n",
      "0.0\n",
      "0.004130006\n",
      "0.0\n",
      "0.00041997433\n",
      "7.998943e-05\n",
      "6.997585e-05\n",
      "0.0\n",
      "\n",
      "Training with 25 EbN0 and lr = 0.00251\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.00251, EbNodB: 25, Iterations: 10000, Repeats: 2\n",
      "0.0\n",
      "0.0064299703\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004639983\n",
      "2.9981136e-05\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Training with 28 EbN0 and lr = 0.00126\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.00126, EbNodB: 28, Iterations: 10000, Repeats: 2\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.998943e-05\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Training with 32 EbN0 and lr = 1e-05\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 1e-05, EbNodB: 32, Iterations: 10000, Repeats: 2\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.001358e-05\n",
      "0.0\n",
      "0.0\n",
      "\n",
      " Done. Training time: 1693.41 sec bzw. 28.22 min\n",
      "\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "# First define Training parameters such as Train-Ebno, Learning Rate, batchsize, validation parameters, repeats\n",
    "train_EbNodB_arr = [3, 7, 11, 13, 17, 22, 25, 28, 32]  \n",
    "lr = np.round(np.linspace(0.01, 0.0001, num=len(train_EbNodB_arr)), 5)\n",
    "batch_size_tr = 1000\n",
    "iterations = 10000\n",
    "repeat = 1  # With that number you force to train on one EbN0 Level multiple times\n",
    "repeats = np.rint(np.linspace(repeat, repeat, num=len(train_EbNodB_arr))).astype(np.int32)\n",
    "val_EbNodB_arr = train_EbNodB_arr\n",
    "\n",
    "# Initialize Model\n",
    "print('Initializing Graph... with M = ' + str(2**k))\n",
    "ae = AE(k, n, seed)\n",
    "print('Initialized... \\n ')\n",
    "\n",
    "# Start training loop\n",
    "t = time.time()\n",
    "train_bler, val_bler = [], []\n",
    "for ind, ebno in enumerate(train_EbNodB_arr, 1):\n",
    "    train_EbNodB = ebno\n",
    "    val_EbNodB = ebno\n",
    "    print('\\nTraining with ' + str(ebno) + ' EbN0 and lr = ' + str(lr[ind-1]))\n",
    "    training_params = [\n",
    "    # batch_size, lr, ebnodb, iterations, repeats\n",
    "    [batch_size_tr, lr[ind-1], train_EbNodB, iterations, repeats[ind-1]]]\n",
    "    validation_params = [\n",
    "    # batch_size, ebnodb, val_steps\n",
    "    [(100*batch_size_tr), val_EbNodB, (iterations/10)]]\n",
    "\n",
    "    ae.train(training_params, validation_params)\n",
    "     \n",
    "elapsed = time.time() - t\n",
    "print('\\n Done. Training time: ' + str(round(elapsed, 2)) + ' sec bzw. ' + str(round(elapsed/60, 2)) + ' min')\n",
    "\n",
    "# Save Model\n",
    "model_file = model_file_1 + 'models/AE' + model_file_2\n",
    "ae.save(model_file)\n",
    "print('\\nModel saved.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsloop 2 (Other possibility, not described in Master's Thesis and not really used)\n",
    "\n",
    "Difference: Variable batchsize and iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-01 1.e-02 1.e-03 1.e-04 1.e-05]\n",
      "Initializing Graph... with M = 4\n",
      "Initialized... \n",
      " \n",
      "\n",
      "Training with 20 EbN0 and lr = 0.1\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.1, EbNodB: 20, Iterations: 5000, Repeats: 1\n",
      "0.93382\n",
      "0.93768\n",
      "0.87082\n",
      "0.93551\n",
      "0.92821\n",
      "0.89441\n",
      "0.81293\n",
      "0.91126\n",
      "0.9219\n",
      "0.77287\n",
      "0.89952\n",
      "\n",
      "Training with 20 EbN0 and lr = 0.01\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.01, EbNodB: 20, Iterations: 5000, Repeats: 1\n",
      "0.93132\n",
      "0.89371\n",
      "0.90275\n",
      "0.81835\n",
      "0.86789\n",
      "0.78429997\n",
      "0.8604\n",
      "0.78323\n",
      "0.72751\n",
      "0.38219\n",
      "0.76373\n",
      "\n",
      "Training with 20 EbN0 and lr = 0.001\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.001, EbNodB: 20, Iterations: 10000, Repeats: 1\n",
      "0.78180003\n",
      "0.48079002\n",
      "0.14365\n",
      "0.23601002\n",
      "0.20468003\n",
      "0.100629985\n",
      "0.0134500265\n",
      "0.0044400096\n",
      "0.086759984\n",
      "0.0021399856\n",
      "0.0\n",
      "\n",
      "Training with 20 EbN0 and lr = 0.0001\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 0.0001, EbNodB: 20, Iterations: 10000, Repeats: 1\n",
      "0.002579987\n",
      "0.0056800246\n",
      "0.009169996\n",
      "0.043940008\n",
      "0.0009999871\n",
      "0.018000007\n",
      "0.00050002337\n",
      "0.50544\n",
      "0.00073999166\n",
      "0.045140028\n",
      "0.00016999245\n",
      "\n",
      "Training with 20 EbN0 and lr = 1e-05\n",
      "\n",
      "Batch Size: 1000, Learning Rate: 1e-05, EbNodB: 20, Iterations: 10000, Repeats: 1\n",
      "0.0023199916\n",
      "0.0069299936\n",
      "0.020889997\n",
      "2.002716e-05\n",
      "0.0014100075\n",
      "1.001358e-05\n",
      "0.0\n",
      "0.0018100142\n",
      "0.00034999847\n",
      "0.011919975\n",
      "0.00019997358\n",
      "\n",
      " Done. Training time: 206.69 sec bzw. 3.44 min\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Define Training parameters\n",
    "train_EbNodB_arr = [20] # [3, ..., 25]\n",
    "lr = np.logspace(-1, -5, 5)\n",
    "iterations = [100, 100, 1000, 1000, 1000]\n",
    "batch_size_tr = 1000\n",
    "repeats_float = np.rint(np.linspace(1, 3, num=len(train_EbNodB_arr)))\n",
    "repeats = np.flip(repeats_float.astype(np.int32), axis=0)\n",
    "val_EbNodB_arr = train_EbNodB_arr\n",
    "\n",
    "# Initialize Model\n",
    "print('Initializing Graph... with M = ' + str(2**k))\n",
    "ae = AE(k, n, seed)\n",
    "print('Initialized... \\n ')\n",
    "\n",
    "# Start Training Loop\n",
    "t = time.time()\n",
    "for lr_i in range(len(lr)):    \n",
    "    for ind, ebno in enumerate(train_EbNodB_arr, 1):\n",
    "        train_EbNodB = ebno\n",
    "        val_EbNodB = ebno\n",
    "        print('\\nTraining with ' + str(ebno) + ' EbN0 and lr = ' + str(lr[lr_i]))\n",
    "        training_params = [\n",
    "        # batch_size, lr, ebnodb, iterations, repeats\n",
    "        [batch_size_tr, lr[lr_i], train_EbNodB, iterations[lr_i], repeats[ind-1]]]\n",
    "        validation_params = [\n",
    "        # batch_size, ebnodb, val_steps\n",
    "        [(100*batch_size_tr), val_EbNodB, (iterations[lr_i]/10)]]\n",
    "    \n",
    "        ae.train(training_params, validation_params)\n",
    "     \n",
    "elapsed = time.time() - t\n",
    "print('\\n Done. Training time: ' + str(round(elapsed, 2)) + ' sec bzw. ' + str(round(elapsed/60, 2)) + ' min')\n",
    "\n",
    "# Save Model\n",
    "model_file = model_file_1 + 'models/AE_loop2' + model_file_2\n",
    "ae.save(model_file)\n",
    "print('\\nModel saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from AE_MIMO_noCSIT/models/AE_k_3_n_1_tx_2_rx_2_s_1\n"
     ]
    }
   ],
   "source": [
    "model_file = model_file_1 + 'models/AE' + model_file_2\n",
    "ae = AE(k, n, mt, mr, seed, filename=model_file) #Load a pretrained model that you have saved if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of learned constellations in one diagramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.plot_constellation()\n",
    "plotfile = model_file_1 + 'Pics/full_const_ae' + model_file_2 + '.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of learned constellations over the different antennas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.plot_const_antwise()\n",
    "plotfile = model_file_1 + 'Pics/const_ants_AE_' + model_file_2 + '.pdf'\n",
    "plt.savefig(plotfile, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot received Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtn = 1  # 0 for received symbols and 1 if after Predecoder-NN\n",
    "ebno = 20\n",
    "numofmsgrepeats= 50\n",
    "y = ae.plot_receive(ebno, numofmsgrepeats, rtn)\n",
    "plotfile = model_file_1 + 'Pics/receive_AE_' + model_file_2 + '_rtn_{}.pdf'.format(rtn)\n",
    "plt.savefig(plotfile, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## BLER Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Simulation... \n",
      "\n",
      "EbN0: 0.0 , Zeit: 1.17min , Averaged over: 1, Absolute Blockerrors: 5751517, BER: 0.28522\n",
      "\n",
      "EbN0: 1.0 , Zeit: 1.77min , Averaged over: 1, Absolute Blockerrors: 5332384, BER: 0.26412\n",
      "\n",
      "EbN0: 2.0 , Zeit: 2.35min , Averaged over: 1, Absolute Blockerrors: 4918873, BER: 0.24318\n",
      "\n",
      "EbN0: 3.0 , Zeit: 2.94min , Averaged over: 1, Absolute Blockerrors: 4441176, BER: 0.21911\n",
      "\n",
      "EbN0: 4.0 , Zeit: 3.52min , Averaged over: 1, Absolute Blockerrors: 3988976, BER: 0.19643\n",
      "\n",
      "EbN0: 5.0 , Zeit: 4.12min , Averaged over: 1, Absolute Blockerrors: 3540418, BER: 0.1742\n",
      "\n",
      "EbN0: 6.0 , Zeit: 4.71min , Averaged over: 1, Absolute Blockerrors: 3125160, BER: 0.15339\n",
      "\n",
      "EbN0: 7.0 , Zeit: 5.3min , Averaged over: 1, Absolute Blockerrors: 2734976, BER: 0.13406\n",
      "\n",
      "EbN0: 8.0 , Zeit: 5.89min , Averaged over: 1, Absolute Blockerrors: 2321914, BER: 0.11358\n",
      "\n",
      "EbN0: 9.0 , Zeit: 6.48min , Averaged over: 1, Absolute Blockerrors: 1953496, BER: 0.09538\n",
      "\n",
      "EbN0: 10.0 , Zeit: 7.07min , Averaged over: 1, Absolute Blockerrors: 1581618, BER: 0.07719\n",
      "\n",
      "EbN0: 11.0 , Zeit: 7.66min , Averaged over: 1, Absolute Blockerrors: 1290415, BER: 0.0629\n",
      "\n",
      "EbN0: 12.0 , Zeit: 8.25min , Averaged over: 1, Absolute Blockerrors: 1030372, BER: 0.05026\n",
      "\n",
      "EbN0: 13.0 , Zeit: 8.84min , Averaged over: 1, Absolute Blockerrors: 791307, BER: 0.0387\n",
      "\n",
      "EbN0: 14.0 , Zeit: 9.44min , Averaged over: 1, Absolute Blockerrors: 616679, BER: 0.03017\n",
      "\n",
      "EbN0: 15.0 , Zeit: 12.36min , Averaged over: 5, Absolute Blockerrors: 2276069, BER: 0.02241\n",
      "\n",
      "EbN0: 16.0 , Zeit: 15.31min , Averaged over: 5, Absolute Blockerrors: 1675292, BER: 0.01659\n",
      "\n",
      "EbN0: 17.0 , Zeit: 18.25min , Averaged over: 5, Absolute Blockerrors: 1202177, BER: 0.01203\n",
      "\n",
      "EbN0: 18.0 , Zeit: 21.12min , Averaged over: 5, Absolute Blockerrors: 874021, BER: 0.00888\n",
      "\n",
      "EbN0: 19.0 , Zeit: 23.99min , Averaged over: 5, Absolute Blockerrors: 606204, BER: 0.00627\n",
      "\n",
      "EbN0: 20.0 , Zeit: 29.71min , Averaged over: 10, Absolute Blockerrors: 843938, BER: 0.00449\n",
      "\n",
      "EbN0: 21.0 , Zeit: 35.49min , Averaged over: 10, Absolute Blockerrors: 578417, BER: 0.00318\n",
      "\n",
      "EbN0: 22.0 , Zeit: 41.35min , Averaged over: 10, Absolute Blockerrors: 389546, BER: 0.00223\n",
      "\n",
      "EbN0: 23.0 , Zeit: 47.27min , Averaged over: 10, Absolute Blockerrors: 273056, BER: 0.00165\n",
      "\n",
      "EbN0: 24.0 , Zeit: 53.2min , Averaged over: 10, Absolute Blockerrors: 194740, BER: 0.00125\n",
      "\n",
      "EbN0: 25.0 , Zeit: 59.07min , Averaged over: 10, Absolute Blockerrors: 130145, BER: 0.00091\n",
      "\n",
      "EbN0: 26.0 , Zeit: 64.77min , Averaged over: 10, Absolute Blockerrors: 95112, BER: 0.00072\n",
      "\n",
      "EbN0: 27.0 , Zeit: 70.51min , Averaged over: 10, Absolute Blockerrors: 71352, BER: 0.00058\n",
      "\n",
      "EbN0: 28.0 , Zeit: 79.1min , Averaged over: 15, Absolute Blockerrors: 72352, BER: 0.00044\n",
      "\n",
      "EbN0: 29.0 , Zeit: 87.65min , Averaged over: 15, Absolute Blockerrors: 54005, BER: 0.00038\n",
      "\n",
      "EbN0: 30.0 , Zeit: 96.28min , Averaged over: 15, Absolute Blockerrors: 42032, BER: 0.00033\n",
      "\n",
      "EbN0: 31.0 , Zeit: 105.04min , Averaged over: 15, Absolute Blockerrors: 39888, BER: 0.00031\n",
      "\n",
      "EbN0: 32.0 , Zeit: 113.85min , Averaged over: 15, Absolute Blockerrors: 34653, BER: 0.00028\n",
      "\n",
      "EbN0: 33.0 , Zeit: 122.66min , Averaged over: 15, Absolute Blockerrors: 27217, BER: 0.00024\n",
      "\n",
      "EbN0: 34.0 , Zeit: 131.48min , Averaged over: 15, Absolute Blockerrors: 23873, BER: 0.00023\n",
      "\n",
      "EbN0: 35.0 , Zeit: 140.29min , Averaged over: 15, Absolute Blockerrors: 23468, BER: 0.00023\n",
      "\n",
      "\n",
      " Done. Simulation time: 8417.24 sec bzw. 140.29 min\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = 100\n",
    "channel_realizations = 10000\n",
    "ti = time.time()\n",
    "\n",
    "# EbN0 Vector\n",
    "ebnodbs = np.linspace(0, 35, 36)\n",
    "\n",
    "# Simulation\n",
    "print('Starting Simulation... \\n')\n",
    "blers = ae.bler_sim(ebnodbs, batch, channel_realizations)\n",
    "ae.plot_bler(ebnodbs, blers)\n",
    "elapsed_1 = time.time() - ti\n",
    "print('\\n Done. Simulation time: ' + str(round(elapsed_1, 2)) + ' sec bzw. ' + str(round(elapsed_1/60, 2)) + ' min')\n",
    "\n",
    "# Save Fig\n",
    "plotfile = model_file_1 + 'Pics/bler_ae' + model_file_2 + '.pdf'\n",
    "plt.savefig(plotfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BER Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done. Simulation time: 34.81 sec bzw. 0.58 min\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = 1000\n",
    "channel_realizations = 10000\n",
    "logfile = model_file_1 + 'Pickle/LOGDATA_BER_ae' + model_file_2 + '.txt'\n",
    "ti = time.time()\n",
    "\n",
    "# EbN0 Vector\n",
    "ebnodbs = np.linspace(0, 35, 36)\n",
    "\n",
    "# Simulation\n",
    "print('Starting Simulation... \\n')\n",
    "_, ber = ae.plot_BER(batch, ebnodbs, channel_realizations, logfile)\n",
    "elapsed_1 = time.time() - ti\n",
    "print('\\n Done. Simulation time: ' + str(round(elapsed_1, 2)) + ' sec bzw. ' + str(round(elapsed_1/60, 2)) + ' min')\n",
    "\n",
    "# Save Fig and BER-Vector in Files\n",
    "plotfile = model_file_1 + 'Pics/BER_ae' + model_file_2 + '.png'\n",
    "plt.savefig(plotfile)\n",
    "\n",
    "pick_file = model_file_1 + 'Pickle/BER_ae' + model_file_2 + '.pckl'\n",
    "f = open(pick_file, 'wb')\n",
    "pickle.dump(ber, f)\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLJ]",
   "language": "python",
   "name": "conda-env-DLJ-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
